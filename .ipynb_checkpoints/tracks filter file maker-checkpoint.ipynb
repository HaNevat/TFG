{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_mpd(os.getcwd() + os.sep  + os.pardir +  \"/MPD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import collections\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import datetime\n",
    "import csv\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg  as la\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of tracks depending on constraints\n",
    "iterates over the million playlist dataset and outputs number songs tha appear more than: 1,2,3,4 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_playlists = 0\n",
    "total_tracks = 0\n",
    "track_histogram = collections.Counter()\n",
    "\n",
    "quick = False\n",
    "max_files_for_quick_processing = 1\n",
    "\n",
    "def process_mpd(path):\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in sorted(filenames):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            process_info(mpd_slice['info'])\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                process_playlist(playlist)\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "\n",
    "    show_summary()\n",
    "\n",
    "\n",
    "def show_summary():\n",
    "    print()\n",
    "    \n",
    " \n",
    "    t1 = len(list(filter(lambda y: y[1]>1, track_histogram.items())))\n",
    "    t2 = len(list(filter(lambda y: y[1]>2, track_histogram.items())))\n",
    "    t3 = len(list(filter(lambda y: y[1]>3, track_histogram.items())))\n",
    "    t4 = len(list(filter(lambda y: y[1]>4, track_histogram.items())))\n",
    "    t5 = len(list(filter(lambda y: y[1]>5, track_histogram.items())))\n",
    "\n",
    "    unique = len(track_histogram)\n",
    "    \n",
    "    print (\"MPD data percentage computed: \"+ str(total_playlists/1000000))\n",
    "    print (\"number of playlists\", total_playlists)\n",
    "    print (\"number of tracks\", total_tracks)\n",
    "    print (\"number of unique tracks appearing ate least once   :\" + str(unique) + \" that is 100%\")\n",
    "    print (\"number of unique tracks appearing more than 1 time :\" + str(t1) + \" that is \"+ str(round(t1/(unique)*100,2))+\"%\" )\n",
    "    print (\"number of unique tracks appearing more than 2 times:\"+ str(t2) + \" that is \"+ str(round(t2/(unique)*100,2))+\"%\" )\n",
    "    print (\"number of unique tracks appearing more than 3 times:\"+ str(t3) + \" that is \"+ str(round(t3/(unique)*100,2))+\"%\"  )\n",
    "    print (\"number of unique tracks appearing more than 4 times:\"+ str(t4) + \" that is \"+ str(round(t4/(unique)*100,2))+\"%\"  )\n",
    "    print (\"number of unique tracks appearing more than 5 times:\"+ str(t5) + \" that is \"+ str(round(t5/(unique)*100,2))+\"%\" )\n",
    "\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r\"[.,\\/#!$%\\^\\*;:{}=\\_`~()@]\", ' ', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "\n",
    "def process_playlist(playlist):\n",
    "    global total_tracks, total_playlists\n",
    "    total_playlists += 1\n",
    "    for track in playlist['tracks']:\n",
    "        total_tracks += 1\n",
    "        track_histogram[track['track_uri']] += 1\n",
    "\n",
    "\n",
    "def process_info(_):\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = sys.argv[1]\n",
    "    if len(sys.argv) > 2 and sys.argv[2] == '--quick':\n",
    "        quick = False\n",
    "    #process_mpd(path)\n",
    "    process_mpd(os.getcwd() + os.sep  + os.pardir +  \"/MPD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    ">1 100%\n",
    ">2 44%\n",
    ">3 30%\n",
    ">4 20%\n",
    ">5 ...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV file maker      _track uri - numeric ID_\n",
    "Makes a csv containing only the tracks appearing more than \"num\" times in the database, and gives each track_uri a numeric ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "in this notebook we will create a csv file with all the tracks_uris and its new associated unique numeric ID\n",
    "only with tracks appearing more than num = 4 times \n",
    "data format: id track_uri\n",
    "usage: process_mpd(path)\n",
    "\"\"\"\n",
    "total_tracks = 0\n",
    "track_histogram = collections.Counter()\n",
    "num = 4\n",
    "\n",
    "quick = False\n",
    "max_files_for_quick_processing = 1\n",
    "\n",
    "def process_mpd(path):\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in sorted(filenames):\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "            for playlist in mpd_slice['playlists']:\n",
    "                process_playlist(playlist)\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "\n",
    "    show_summary()\n",
    "    write_file()\n",
    "\n",
    "def write_file():\n",
    "    j = 0\n",
    "    with open('id_trackuri_filter.csv', 'w', newline='') as csvfile:\n",
    "        spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        spamwriter.writerow([\"id\",\"track_uri\"])\n",
    "        for track in track_histogram.items():\n",
    "            if track[1]>num:\n",
    "                spamwriter.writerow([j,track[0][14:]])\n",
    "                j+=1\n",
    "        \n",
    "\n",
    "def show_summary():\n",
    "    t1 = len(list(filter(lambda y: y[1]>4, track_histogram.items())))\n",
    "    print(\"number of tracks\", total_tracks)\n",
    "    print(\"number of unique tracks\", len(track_histogram))\n",
    "    print(\"saved tracks in file, with num_appearences>\"+str(num)+\" times: \"+ str(t1) +\n",
    "          \" that is \"+ str(round(t1/len(track_histogram)*100,2))+\"%\" )\n",
    "\n",
    "\n",
    "def process_playlist(playlist):\n",
    "    global total_tracks\n",
    "    for track in playlist['tracks']:\n",
    "        total_tracks += 1\n",
    "        track_histogram[track['track_uri']] += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = sys.argv[1]\n",
    "    if len(sys.argv) > 2 and sys.argv[2] == '--quick':\n",
    "        quick = False\n",
    "    #process_mpd(path)\n",
    "    process_mpd(os.getcwd() + os.sep  + os.pardir +  \"/MPD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data slices with playists by id\n",
    "creates a new set of data slices with less information than the original one\n",
    "specifically, for each slice, it will create a csv file containing its 1000 playlists, with only the\n",
    "tracks tha apear more than \"num\" times in the whole dataset, each track written as a numeric ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick = False\n",
    "max_files_for_quick_processing = 2\n",
    "#csv to dict\n",
    "reader = csv.reader(open('id_trackuri_filter.csv', 'r'))\n",
    "dict_trackuri_ids = {v:k for (k,v) in reader}\n",
    "\n",
    "def process_mpd(path):\n",
    "    count = 0 # slices counter\n",
    "    i=0       # playlists counter   \n",
    "    filenames = os.listdir(path)\n",
    "    \n",
    "    #for each slice\n",
    "    for filename in sorted(filenames):\n",
    "        #read slice\n",
    "        if filename.startswith(\"mpd.slice.\") and filename.endswith(\".json\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            f = open(fullpath)\n",
    "            js = f.read()\n",
    "            f.close()\n",
    "            mpd_slice = json.loads(js)\n",
    "\n",
    "            #process slice and write a csv \n",
    "            with open('../MPD_filter_ids/playlists_tracks_id_'+str(count)+'.csv', 'w', newline='',encoding=\"utf-8\") as csvfile:\n",
    "                spamwriter = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "                spamwriter.writerow([\"playlist\",\"track_id\"])\n",
    "                for playlist in mpd_slice['playlists']:\n",
    "                    for track in playlist[\"tracks\"]:\n",
    "                        uri = track[\"track_uri\"][14:]\n",
    "                        if uri in dict_trackuri_ids.keys():\n",
    "                            spamwriter.writerow([i, dict_trackuri_ids[uri]])\n",
    "                    i+=1\n",
    "        count += 1\n",
    "\n",
    "        if quick and count > max_files_for_quick_processing:\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = sys.argv[1]\n",
    "    if len(sys.argv) > 2 and sys.argv[2] == '--quick':\n",
    "        quick = False\n",
    "    #process_mpd(path)\n",
    "    process_mpd(os.getcwd() + os.sep  + os.pardir +  \"/MPD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrix\n",
    "Makes a matrix tracks x tracks with the number of occurences in the same playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebooks creates and saves into a file sparse_matrix_filter.npz a sparse matrix tracks x tracks\n",
    "containing the total amount of times 2 tracks appear in the same playlist\n",
    "usage: run after running FILE CREATOR - playlist by id, so that the file playlists_tracks_id.csv is in the same folder\n",
    "\"\"\"\n",
    "quick = True\n",
    "max_files_for_quick_processing = 2\n",
    "size_matrix = 133500 #number of unique songs in 10% MPD filtered \n",
    "matrix = sp.coo_matrix((size_matrix, size_matrix), [np.int64])\n",
    "\n",
    "def process_mpd(path):\n",
    "    count = 0\n",
    "    filenames = os.listdir(path)\n",
    "    for filename in sorted(filenames):\n",
    "        if filename.startswith(\"playlists_tracks_id_\") and filename.endswith(\".csv\"):\n",
    "            fullpath = os.sep.join((path, filename))\n",
    "            process_slice(fullpath)\n",
    "            #df = pd.read_csv(fullpath)\n",
    "            #process_slice(df)\n",
    "            count += 1\n",
    "\n",
    "            if quick and count > max_files_for_quick_processing:\n",
    "                break\n",
    "                \n",
    "        sp.save_npz('sparse_matrix_filter.npz', matrix)\n",
    "\n",
    "\n",
    "def process_slice(fullpath):\n",
    "    df = pd.read_csv(fullpath)\n",
    "    i = 0 # playlist iterator\n",
    "    j = 0 # row from csv iterator\n",
    "    length_csv = len(df)\n",
    "    play = []\n",
    "    global matrix\n",
    "    \n",
    "    while j<length_csv:\n",
    "        if df[\"playlist\"][j]==i:\n",
    "            play.append(df[\"track_id\"][j])\n",
    "            j+=1\n",
    "        else:\n",
    "            #we make a sparse matrix out of the ith playlist\n",
    "            combinations = list(itertools.product(play,play)) #TODO: CONSIDER PAIRS ONLY ONCE!!!\n",
    "            row = np.array([m for (m,n) in combinations])\n",
    "            col = np.array([n for (m,n) in combinations])\n",
    "            n = (len(row))\n",
    "            listones = list(np.ones(len(row), dtype=np.int64))\n",
    "            mat = sp.csc_matrix((listones, (row, col)), shape=(size_matrix,size_matrix))\n",
    "\n",
    "            #adds up the matrix to the final sparse matrix\n",
    "            matrix +=mat\n",
    "\n",
    "            #cleans the list for the next playlist\n",
    "            play = []\n",
    "            i+=1\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = sys.argv[1]\n",
    "    if len(sys.argv) > 2 and sys.argv[2] == '--quick':\n",
    "        quick = True\n",
    "    #process_mpd(path)\n",
    "    process_mpd(os.getcwd() + os.sep  + os.pardir +  \"/MPD_filter_ids\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_npz('sparse_matrix_filter.npz', matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../MPD_filter_ids/playlists_tracks_id_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"playlist\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60235"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix[378843,172352])\n",
    "print(matrix[75800,65296])\n",
    "print(matrix[267752,43983])\n",
    "print(matrix[33101,33101])\n",
    "print(matrix.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
